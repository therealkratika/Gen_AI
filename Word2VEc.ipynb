{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Word Embedding: dense vector representation of a word that captures meaning.\n",
        "\n",
        "Word2Vec: technique in NLP used to represent word as dense numerical vector\n",
        "\n",
        "It allows machine to understand the semantic relationship between words by positioning similar words together\n"
      ],
      "metadata": {
        "id": "e9s9mAVojxnR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpVRcukSjgQA",
        "outputId": "467ecba7-a764-4220-99cf-633ca9261f8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.1.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install gensim\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences =[\n",
        "    \"i am learning Natural Language Processing\",\n",
        "    \"Natural language processing is a part of machine learning\",\n",
        "    \"i am also learning machine learning\",\n",
        "    \"i want to learn machine learning\",\n",
        "    \"Deep Learning uses neural network\",\n",
        "    \"Neural network is a part of machine learning\"\n",
        "]\n",
        "\n",
        "tokenized_sentences = [word_tokenize(s.lower()) for s in sentences]\n",
        "print(tokenized_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgAH4YdCj2G_",
        "outputId": "ab2e9d4a-2214-4c38-e3d3-b0cbcadc5ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['i', 'am', 'learning', 'natural', 'language', 'processing'], ['natural', 'language', 'processing', 'is', 'a', 'part', 'of', 'machine', 'learning'], ['i', 'am', 'also', 'learning', 'machine', 'learning'], ['i', 'want', 'to', 'learn', 'machine', 'learning'], ['deep', 'learning', 'uses', 'neural', 'network'], ['neural', 'network', 'is', 'a', 'part', 'of', 'machine', 'learning']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " vector_size=100: Each word becomes a 100-dimensional vector.\n",
        "\n",
        "    window=3: Looks at 3 words before and after the target word as context.\n",
        "\n",
        "    min_count=1: Keep all words (even rare ones).\n"
      ],
      "metadata": {
        "id": "M7r9-fKWkDGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=Word2Vec(\n",
        "    sentences=tokenized_sentences,\n",
        "    vector_size=100, #embedding dimension-dimension of word vector\n",
        "    window=3, #context window size- max dist between target and context\n",
        "    min_count=1 #keep all words\n",
        ")"
      ],
      "metadata": {
        "id": "56KI5cMhj-NF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.wv.similarity(\"deep\",\"learning\"))  #similarity score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4HVM0y-kIeP",
        "outputId": "984415cd-ae5e-441d-dc5b-78ebcf89d01b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.037719585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#similar words\n",
        "print(model.wv.most_similar(\"learning\",topn=5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8GATS8YkKr2",
        "outputId": "e34f324d-a58f-4466-d7e8-f01b723a8f0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('to', 0.21883945167064667), ('processing', 0.21617600321769714), ('am', 0.0931011214852333), ('a', 0.09295263886451721), ('natural', 0.07963486760854721)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How it works internally:\n",
        "\n",
        "A sliding window moves across your text.\n",
        "\n",
        "For each target word, the network tries to predict context words (Skip-gram) or predict the target from context words (CBOW).\n",
        "\n",
        "During training, it learns weights that become your embedding vectors.\n",
        "\n",
        "Shallow neural network: One hidden layer → the hidden layer weights are your word vectors"
      ],
      "metadata": {
        "id": "yIWU9e_skNLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Internally -> model slides window across text\n",
        "# LEARN WEIGHTS VIA NEURAL NETWORK\n",
        "# PRODUCES EMBEDDING MATRIX"
      ],
      "metadata": {
        "id": "G5qmaR8hkMbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "WORD2VEC IS A SHALLOW NEURAL NETWORK WITH ONE HIDDEN LAYER ONLY\n",
        "\n",
        "LIMITATION: STATIC EMBEDDING(SAME VECTOR FOR EVERY CONTEXT)\n",
        "NEEDS LARGE DATASET TO FUNCTION PROPERLY"
      ],
      "metadata": {
        "id": "skokRjGikW5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#USING PRETRAINED EMBEDDINGS\n",
        "# 2. popular pretrained model\n",
        "#1. google news Word2Vec (300)\n",
        "#2. GloVe (Stanford)\n",
        "import gensim.downloader as api\n",
        "print(\"Loading pretrained models:\")\n",
        "model=api.load(\"word2vec-google-news-300\")\n",
        "# model=api.load(\"glove-wiki-gigaword-100\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLF8T0ZfkXYU",
        "outputId": "3b27d646-8724-47c7-b6a8-33d45fa86aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pretrained models:\n",
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.similarity(\"artificial\",\"intelligence\"))\n",
        "\n",
        "print(model.most_similar(\"happy\",topn=15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FsPh0wWkdJw",
        "outputId": "064a6af4-1be0-4cc2-a540-43002eba48d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0064100265\n",
            "[('glad', 0.7408890724182129), ('pleased', 0.6632170677185059), ('ecstatic', 0.6626912355422974), ('overjoyed', 0.6599286794662476), ('thrilled', 0.6514049172401428), ('satisfied', 0.6437949538230896), ('proud', 0.636042058467865), ('delighted', 0.627237856388092), ('disappointed', 0.6269949674606323), ('excited', 0.6247665286064148), ('happier', 0.6244627237319946), ('Said_Hirschbeck', 0.6234508752822876), ('elated', 0.6196017861366272), ('thankful', 0.6178935766220093), ('unhappy', 0.6128038167953491)]\n"
          ]
        }
      ]
    }
  ]
}